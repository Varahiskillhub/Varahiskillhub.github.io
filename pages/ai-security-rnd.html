<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>AI Security R&amp;D — Bala Donthamsetti</title>
  <link rel="stylesheet" href="../assets/style.css"/>
</head>
<body>
  <div class="wrap">
    <div class="nav">
      <div class="brand"><a href="../index.html">← Home</a></div>
      <div class="navlinks">
        <a href="projects.html">Projects</a>
        <a href="../index.html#contact">Contact</a>
      </div>
    </div>

    <div class="section">
      <h2>AI‑Assisted Security Automation (Peregrine)</h2>
      <p class="small">
        Portfolio summary (sanitised). This focuses on engineering and security workflow improvements —
        not claiming academic “AI research”.
      </p>

      <div class="grid">
        <div class="card">
          <h3>Problem</h3>
          <p>
            Security testing often becomes slow and expensive: lots of recon noise, repeated manual steps,
            and inconsistent reporting quality across targets.
          </p>
        </div>

        <div class="card">
          <h3>What I built</h3>
          <ul>
            <li>LLM‑assisted workflow to speed up recon → hypothesis → targeted tests → evidence → report draft.</li>
            <li>Modular “runner” design so tests can be added as plugins.</li>
            <li>Evidence‑first outputs: requests, responses, screenshots/notes, and clear repro steps.</li>
          </ul>
        </div>

        <div class="card">
          <h3>Key design choices</h3>
          <ul>
            <li><strong>Cost control:</strong> model routing (cheap for summarisation, stronger models for reasoning), caching, offline mode for heavy steps.</li>
            <li><strong>Reproducibility:</strong> deterministic validation steps where possible, artefact saving, structured outputs.</li>
            <li><strong>False‑positive control:</strong> confidence scoring + “must verify” rules before reporting.</li>
          </ul>
        </div>

        <div class="card">
          <h3>Guardrails / responsible use</h3>
          <ul>
            <li>Scope enforcement (allowed domains, rate limits, stop conditions).</li>
            <li>No sensitive data in portfolio: sanitised demos and redacted examples only.</li>
            <li>Logging designed for audits (what was tested, when, and why).</li>
          </ul>
        </div>

        <div class="card">
          <h3>Tech stack</h3>
          <ul>
            <li>Python orchestration</li>
            <li>HTTP + browser automation (where required)</li>
            <li>Local / hosted LLM providers (swappable adapters)</li>
            <li>Structured storage for findings + artefacts</li>
          </ul>
        </div>

        <div class="card">
          <h3>Next improvements</h3>
          <ul>
            <li>Evaluation harness for prompts/tools (precision/recall, cost per validated finding).</li>
            <li>Better auth flows support (session replay, token refresh helpers).</li>
            <li>More “target‑aware” tests (tech fingerprint → focused modules).</li>
          </ul>
        </div>
      </div>

      <hr/>
      <p class="small">
        If you’d like a deeper walkthrough, I can share a high‑level architecture diagram and a sanitised demo flow.
      </p>
    </div>
  </div>
</body>
</html>
